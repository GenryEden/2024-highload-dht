# 6 стадия, Емельянов Виталий

Профилирование проводилось на 
данных объемом 1.4 ГиБ, ~10'000 SSTable.

Полезная нагрузка (объем данных, считанных curl'ом) - 
408 МиБ.

## ЦПУ

[Профиль ЦПУ](range_cpu.html)

Из наших тредов (т.е. без gc и без компилятора)
можно выделить 4 основных сотавляющих - отправка полезной нагрузки (43%),
отправка знака переноса (43%), поиск следующего вхождения в итераторе (7.5%),
исходное позиционирование (0.95%).

Четко видно, что перенос строки, несмотря на то, что данных в нем намного меньше,
чем в полезной нагрузке, занимает схожее значение сэмплов, поэтому попробуем 
отправлять их разом.

[Профиль ЦПУ после модификации](range_cpu_new.html)

Здесь и далее на профилях могут работать несколько потоков. Так происходит, потому
что curl запускался автоматически в цикле и время профилирования было больше, нежели время работы curl.

Скорость загрузки (по curl) выросла в 4-5 раз (до 20 МиБ/c на первый запуск и 25 МиБ/c на последующие).

Теперь на работу с сокетом ушло 63% сэмплов, на работу компаратора 25%, на выделение нового MemorySegment
из файлового - 6%.

Далее мы будем рассматривать только модифицированную версию, потому что изначальная была глупостью,
вызванной надеждой на то, что алгоритм Нейгла или что-нибудь аналогичное сработает на цепочке работы с сетвым стеком.
Это было наивно.

## Аллокации

[Профиль аллокаций](range_alloc_new.html)

Здесь мне очень не понравилось, что мы сначала копируем из MemorySegment в массив, 
из которого перекладываем в другой массив. В HttpChunkedEntry ввел такую функцию.

```java
private static int copy(MemorySegment from, byte[] to, int destOffset) {
    for (int i = 0; i < from.byteSize(); i++) {
        to[i + destOffset] = from.getAtIndex(ValueLayout.JAVA_BYTE, i);
    }
    return (int) from.byteSize();
}
```

Ей пришлось пользоваться, поскольку MemorySegment не имеет метода для копирования
в существующий массив. Но это в свою очередь ударило по ЦПУ, что видно про [профилю](range_cpu_new_2.html),
где данный метод использует ~7.5% сэмплов. Это приводит не к прям трагичному падению (~0.5 МиБ/с по curl), но неприятно,
поэтому в репозитории было решено оставить изначальное решение с таким двойным копированием.

С другой стороны, это сильно сокращает потребление по аллокациям у HttpChunkedEntry.write (60% -> 40%).

[Профиль по аллокациям с применением этой функции](range_alloc_new_2.html)


Оставшиеся аллокации происходят в dao и на создание самого объекта HttpChunkedEntry.

## Локи

[Локов нету](range_lock_new.html)

